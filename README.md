# GridSight âš¡

**Advanced Energy Market Data Pipeline & Analytics Platform**

GridSight is a comprehensive data science project that ingests, processes, and analyzes Ontario's electricity market data from the Independent Electricity System Operator (IESO). The platform provides insights into energy demand patterns, generator output, and locational marginal pricing across the Ontario electricity grid.

## ğŸ¯ Project Overview

**Domain**: Energy Market Analysis & Grid Operations  
**Data Sources**: IESO Public Data  
**Architecture**: Cloud-based data lake with Azure Blob Storage  
**Timeline**: January 2025 - May 2025 (5 months of market data)  
**Scale**: 500,000+ time series records across multiple energy dimensions

## ğŸ“Š Current Project Status

âœ… **Phase 1: Data Ingestion (COMPLETE)**  
âœ… **Phase 2: Data Cleaning & Processing (COMPLETE)**  
ğŸ”„ **Phase 3: Database Integration (Next)**  
â³ **Phase 4: Modeling & Analytics (Planned)**  
â³ **Phase 5: Visualization & Insights (Planned)**

## ğŸ”§ Setup & Configuration

### Prerequisites
```bash
pip install -r requirements.txt
```

### Azure Storage Setup
1. **Copy the configuration template**:
   ```bash
   cp config_template.py config.py
   ```

2. **Fill in your Azure credentials** in `config.py`:
   ```python
   ACCOUNT_NAME = "your_azure_storage_account"
   ACCOUNT_KEY = "your_azure_storage_key"
   ```

3. **Update placeholder values** in Python files:
   - Replace `YOUR_AZURE_STORAGE_ACCOUNT` with your account name
   - Replace `YOUR_AZURE_STORAGE_KEY_HERE` with your storage key

âš ï¸ **Security Note**: Never commit actual Azure credentials to version control. The `config.py` file is ignored by git.

## ğŸ—ï¸ Data Architecture

### Raw Data Pipeline
```
IESO Public APIs â†’ Azure Blob Storage ("raw-data") â†’ Processing Scripts â†’ Azure Blob Storage ("cleaned-data")
```

### Data Lake Structure
```
ğŸ“ raw-data/
â”œâ”€â”€ ğŸ“ Demand/year=2025/month=XX/day=XX/
â”œâ”€â”€ ğŸ“ ZonalDemand/year=2025/month=XX/day=XX/
â”œâ”€â”€ ğŸ“ GenMix/year=2025/month=XX/day=XX/
â”œâ”€â”€ ğŸ“ EnergyLMP/year=2025/month=XX/day=XX/
â””â”€â”€ ğŸ“ IntertieLMP/year=2025/month=XX/day=XX/

ğŸ“ cleaned-data/
â”œâ”€â”€ ğŸ“ Demand/year=2025/month=XX/day=XX/
â”œâ”€â”€ ğŸ“ ZonalDemand/year=2025/month=XX/day=XX/
â”œâ”€â”€ ğŸ“ GenMix/year=2025/month=XX/day=XX/
â”œâ”€â”€ ğŸ“ EnergyLMP/year=2025/month=XX/day=XX/
â””â”€â”€ ğŸ“ IntertieLMP/year=2025/month=XX/day=XX/
```

## ğŸ“ˆ Data Sources & Metrics

| Dataset | Format | Records | Time Period | Description |
|---------|--------|---------|-------------|-------------|
| **Demand** | CSV | ~36,000 | Jan-May 2025 | Provincial electricity demand (5-min intervals) |
| **ZonalDemand** | CSV | ~360,000 | Jan-May 2025 | Demand by transmission zone (5-min intervals) |
| **GenMix** | XMLâ†’CSV | ~21,000 | Jan-May 2025 | Generator output by fuel type (hourly) |
| **EnergyLMP** | CSV | ~36,000 | May 2025 | Locational marginal pricing (5-min intervals) |
| **IntertieLMP** | XMLâ†’CSV | ~25,000 | May 2025 | Intertie connection pricing (5-min intervals) |

## ğŸ› ï¸ Technical Implementation

### Key Technologies
- **Cloud Storage**: Azure Blob Storage
- **Data Processing**: Python, Pandas, XML parsing
- **API Integration**: IESO Public Data APIs
- **Version Control**: Git/GitHub
- **Planned**: DuckDB, Machine Learning, Visualization

### Processing Pipeline Features
- **Memory-efficient processing**: Direct blob-to-blob transformation without local storage
- **Multi-format handling**: CSV and XML data processing
- **Timestamp standardization**: UTC timezone management
- **Data quality preservation**: Flag retention for quality tracking
- **Automated backfill**: Historical data ingestion with date filtering

## ğŸ“‚ Project Structure

```
GridSight/
â”œâ”€â”€ ğŸ“ azure_push_clean/          # Data cleaning & upload scripts
â”‚   â”œâ”€â”€ pub_demand_cleaned_push.py
â”‚   â”œâ”€â”€ demand_zonal_clean_push.py
â”‚   â”œâ”€â”€ genmix_clean_push.py
â”‚   â”œâ”€â”€ energyLMP_clean_push.py
â”‚   â”œâ”€â”€ intertielmp_push_clean.py
â”‚   â””â”€â”€ verify_intertie_cleaned.py
â”œâ”€â”€ ğŸ“ backfill_script_uncleaned/  # Raw data ingestion scripts
â”‚   â”œâ”€â”€ backfill_demand.py
â”‚   â”œâ”€â”€ backfill_zonal.py
â”‚   â”œâ”€â”€ backfill_genmix.py
â”‚   â”œâ”€â”€ backfill_energy_lmp.py
â”‚   â””â”€â”€ backfill_intertie_lmp.py
â”œâ”€â”€ ğŸ“ call_azure_cleanstep1/      # Download utilities
â”‚   â”œâ”€â”€ call_demand.py
â”‚   â”œâ”€â”€ call_genmix.py
â”‚   â”œâ”€â”€ call_energylmp.py
â”‚   â””â”€â”€ call_intertie_lmp.py
â”œâ”€â”€ ğŸ“ data_explore/               # Data exploration & analysis
â”‚   â”œâ”€â”€ pub_demand_explore.py
â”‚   â”œâ”€â”€ Demand_Zonal_Explore.py
â”‚   â”œâ”€â”€ GenMix_explore.py
â”‚   â”œâ”€â”€ Energy_LMP_Explore.py
â”‚   â””â”€â”€ intertie_lmp_explore.py
â”œâ”€â”€ ğŸ“ lmp_cleaned/               # Local cleaned data cache
â”œâ”€â”€ config_template.py            # Azure credentials template
â”œâ”€â”€ project_roadmap.txt           # Detailed project roadmap
â”œâ”€â”€ schema_1.txt                  # Database schema design
â””â”€â”€ README.md                     # This file
```

## ğŸ” Data Quality & Insights

### Processing Achievements
- **âœ… 23/24 IntertieLMP files processed** (95.8% success rate)
- **âœ… Multi-hour data handling** (5 hours per file, 1,080 records each)
- **âœ… Timestamp accuracy** (5-minute interval precision)
- **âœ… Geographic parsing** (18 intertie connections across 8 jurisdictions)

### Key Data Insights Discovered
- **IntertieLMP Analysis**: 94.6% of LMP values are zero (inactive connections)
- **Active Interties**: Only MB.WHITESHELL and MN.INTFALLS show consistent pricing
- **Jurisdictional Coverage**: Connections to Quebec (PQ), Manitoba (MB), New York (NY), Maryland (MD), Michigan (MI), Minnesota (MN), East Coast (EC), West Coast (WC)
- **Data Quality**: All records flagged as "DSO-RD" (Dispatch Scheduling Optimizer - Resource Decommitment)

## ğŸš€ Recent Accomplishments

### Data Ingestion Optimizations
- **Storage Efficiency**: Reduced data storage by ~97% through latest-daily-file selection
- **Fixed Timezone Issues**: Resolved datetime comparison errors in backfill scripts
- **XML Processing**: Successfully parsed complex GenMix and IntertieLMP XML structures
- **Memory Management**: Implemented direct blob-to-blob processing for large datasets

### Advanced Data Transformations
- **Timestamp Creation**: Calculated precise timestamps from delivery dates + intervals
- **Name Parsing**: Extracted location/connection info from intertie identifiers
- **Multi-format Support**: Unified CSV and XML data into consistent schemas
- **Quality Preservation**: Maintained data quality flags throughout processing

## ğŸ“‹ Database Schema (Planned)

```sql
-- Demand Table
CREATE TABLE demand (
    timestamp TIMESTAMP,
    ontario_demand FLOAT,
    file_source VARCHAR(255)
);

-- ZonalDemand Table  
CREATE TABLE zonal_demand (
    timestamp TIMESTAMP,
    zone VARCHAR(50),
    demand FLOAT
);

-- GenMix Table
CREATE TABLE genmix (
    timestamp TIMESTAMP,
    fuel_type VARCHAR(50),
    energy_output FLOAT
);

-- EnergyLMP Table
CREATE TABLE energy_lmp (
    timestamp TIMESTAMP,
    interval INTEGER,
    lmp_value FLOAT
);

-- IntertieLMP Table
CREATE TABLE intertie_lmp (
    timestamp TIMESTAMP,
    intertie_name VARCHAR(100),
    location VARCHAR(10),
    connection VARCHAR(50),
    code VARCHAR(20),
    interval_set INTEGER,
    interval INTEGER,
    lmp_value FLOAT,
    flag VARCHAR(20)
);
```

## ğŸ¯ Next Steps

### Phase 3: Database Integration
- [ ] Set up DuckDB for analytics
- [ ] Implement data ingestion from cleaned blobs
- [ ] Create joined tables for cross-dataset analysis
- [ ] Build automated data quality checks

### Phase 4: Advanced Analytics
- [ ] Demand forecasting models
- [ ] Intertie flow analysis
- [ ] Price correlation studies
- [ ] Generator efficiency analysis

### Phase 5: Visualization & Insights
- [ ] Interactive dashboards
- [ ] Time series visualizations
- [ ] Geographic grid mapping
- [ ] Real-time monitoring capabilities

## ğŸ”§ Running Data Processing

### Clean and upload specific dataset
```bash
python azure_push_clean/intertielmp_push_clean.py
```

### Explore data structure
```bash
python data_explore/intertie_lmp_explore.py
```

## ğŸ“Š Project Metrics

- **ğŸ“ˆ Data Volume**: 500,000+ time series records
- **ğŸŒ Geographic Coverage**: 8 jurisdiction connections  
- **â±ï¸ Temporal Resolution**: 5-minute intervals
- **ğŸ“… Historical Depth**: 5 months (Jan-May 2025)
- **â˜ï¸ Cloud Architecture**: 100% Azure-based data lake
- **ğŸ”„ Processing Efficiency**: 95%+ success rate

## ğŸ¤ Contributing

This project demonstrates advanced data engineering practices in the energy sector. Key learning areas include:
- Complex multi-format data integration
- Cloud-native data pipeline design
- Energy market domain expertise
- Time series data management
- Azure blob storage optimization

## ğŸ“œ License

This project is for educational and research purposes, utilizing publicly available IESO data.

---

**GridSight** - *Illuminating Ontario's Energy Market Through Data Science*

ğŸ”— **Data Source**: [IESO Public Data](http://reports.ieso.ca/)  
ğŸ“§ **Contact**: [GitHub Issues](https://github.com/yugant99/GridSight/issues) 